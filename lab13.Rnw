\documentclass{article}
\usepackage[margin=1.0in]{geometry} % To set margins
\usepackage{amsmath}  % This allows me to use the align functionality.
                      % If you find yourself trying to replicate
                      % something you found online, ensure you're
                      % loading the necessary packages!
\usepackage{amsfonts} % Math font
\usepackage{fancyvrb}
\usepackage{hyperref} % For including hyperlinks
\usepackage[shortlabels]{enumitem}% For enumerated lists with labels specified
                                  % We had to run tlmgr_install("enumitem") in R
\usepackage{float}    % For telling R where to put a table/figure
\usepackage{natbib}        %For the bibliography
\bibliographystyle{apalike}%For the bibliography

\begin{document}
<<echo=F, message=F, warning=F>>=
library(tidyverse)
library(xtable)
library(VGAM)
library(e1071)
library(pwr)
library(effectsize)
library(boot)
@

\begin{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Question 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item When conducting the work of Lab 11, we conducted the test that uses the
Central Limit Theorem even though the sample size was ``small" (i.e., $n<30$).
It turns out, that how ``far off" the $t$-test is can be computed using
a first-order Edgeworth approximation for the error. Below, we will do this 
for the the further observations.
\begin{enumerate}
  \item \cite{Boos00} note that 
  \begin{align*}
    P(T \leq t) \approx F_Z(t) + \underbrace{\frac{\text{skew}}{\sqrt{n}} \frac{(2t^2+1)}{6} f_Z(t)}_{\textrm{error}},
  \end{align*}
  where $f_Z(\cdot)$ and $F_Z(\cdot)$ are the Gaussian PDF and CDF and skew is the
  skewness of the data. What is the potential error in the computation of the 
  $p$-value when testing $H_0: \mu_X=0; H_a: \mu_X<0$ using the zebra finch further data?
<<message=F, warning=F, eval=T>>=
data <- read_csv("zebrafinches.csv")

mu0 <- 0
t.stat <- t.test(data$further,
                    mu = mu0,
                    alternative = "less")
t.further <- t.stat$statistic

n <- length(data$further)

skewness <- skewness(data$further)
fz <- dnorm(t.further)
Fz <- pnorm(t.further)

(edgeworth.error <- (skewness/sqrt(n)) * (((2*(t.further)^2 + 1)/6)*(fz)))

(probability <- Fz + edgeworth.error)
@

The probability is \Sexpr{probability} and the Edgeworth approximation is \Sexpr{edgeworth.error}. As the value of the Edgeworth approximation is small, the t-test can be said to be \textbf{NOT} "far off".

  \item Compute the error for $t$ statistics from -10 to 10 and plot a line
  that shows the error across $t$. Continue to use the skewness and 
  the sample size for the zebra finch further data.
  
<<message=F, warning=F, eval=T>>=
t.vals <- seq(-10,10, length = 1000)
fzb <- dnorm(t.vals)

error.vals <- (skewness/sqrt(n)) * (((2*(t.vals)^2 + 1)/6)*(fzb))

tvals.error <- tibble(
  t = t.vals,
  error = error.vals
)

ggplot()+
  geom_line(data = tvals.error,
            aes(x = t, y = error),
            color = "red")+
  theme_bw()+
  labs(title = "Edgeworth Approximation For Error",
       x = "T Values (-10,10)",
       y = "Error")
@

The plot looks like a \textbf{W}. The plot shows that t values $<5$ and $>5$ are zero. The most error 

  \item Suppose we wanted to have a tail probability within 10\% of the desired
  $\alpha=0.05$. Recall we did a left-tailed test using the further data.
  How large of a sample size would we need? That is, we need
  to solve the error formula equal to 10\% of the desired left-tail probability:
  \[0.10 \alpha  \stackrel{set}{=} \underbrace{\frac{\text{skew}}{\sqrt{n}} \frac{(2t^2+1)}{6} f_Z(t)}_{\textrm{error}},\]
  which yields
  \[ n = \left(\frac{\text{skew}}{6(0.10\alpha)} (2t^2 + 1) f_Z(t)\right)^2.\]

<<message=F, warning=F, eval=T>>=  
val.t <- qnorm(0.05)
fzc <- dnorm(val.t)

(n <- ((skewness/(6*(0.10*0.05))) * (2*val.t^2 + 1) *fzc)^2)
@
The sample size needed to reach $\alpha = 0.05$ is \Sexpr{n}. To reach 10\% of $\alpha = 0.05$, we will need a much larger sample than the 25 taken in the study.
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Question 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item Complete the following steps to revisit the analyses from lab 11 using the
bootstrap procedure.
\begin{enumerate}
\item Now, consider the zebra finch data. We do not know the generating distributions
for the closer, further, and difference data, so perform resampling to approximate the 
sampling distribution of the $T$ statistic:
  \[T = \frac{\bar{x}_r - 0}{s/\sqrt{n}},\]
  where $\bar{x}_r$ is the mean computed on the r$^{th}$ resample and $s$ is the
  sample standard deviation from the original samples. At the end, create an
  object called \texttt{resamples.null.closer}, for example, and store the 
  resamples shifted to ensure they are consistent with the null hypotheses at the average 
  (i.e., here ensure the shifted resamples are 0 on average, corresponding
  to $t=0$, for each case).
<<message=F, warning=F, eval=T>>=    
R <- 10000
sd.closer <- sd(data$closer)
num.closer <- length(data$closer)
resamples.closer <-  tibble(tstat=rep(NA, R),
                            xbar=rep(NA, R))
for(i in 1:R){
  curr.resample <- sample(x = data$closer,
                          size = num.closer,
                          replace = T)
  resamples.closer$tstat[i] <- (mean(curr.resample)-0)/(sd.closer/sqrt(num.closer))
  resamples.closer$xbar[i] <- mean(curr.resample)
}


closer.delta <- mean(resamples.closer$tstat) - 0

resamples.null.closer <- resamples.closer |>
  mutate(shifted = tstat - closer.delta)

R <- 10000
sd.further <- sd(data$further)
num.further <- length(data$further)
resamples.further <- tibble(tstat=rep(NA, R),
                            xbar=rep(NA, R))
for(i in 1:R){
  curr.resample <- sample(x = data$further,
                          size = num.further,
                          replace = T)
  resamples.further$tstat[i] <- (mean(curr.resample)-0)/(sd.further/sqrt(num.further))
  resamples.further$xbar[i] <- mean(curr.resample)
}


further.delta <- mean(resamples.further$tstat) - 0

resamples.null.further <- resamples.further |>
  mutate(shifted = tstat - further.delta)

R <- 10000
sd.diff <- sd(data$diff)
num.diff <- length(data$diff)
resamples.diff <-  tibble(tstat=rep(NA, R),
                          xbar=rep(NA, R))
for(i in 1:R){
  curr.resample <- sample(x = data$diff,
                          size = num.diff,
                          replace = T)
  resamples.diff$tstat[i] <- (mean(curr.resample)-0)/(sd.diff/sqrt(num.diff))
  resamples.diff$xbar[i] <- mean(curr.resample)
}

diff.delta <- mean(resamples.diff$tstat) - 0
resamples.null.diff <- resamples.diff |>
  mutate(shifted = tstat - diff.delta)

(mean(resamples.null.closer$shifted))
(mean(resamples.null.further$shifted))
(mean(resamples.null.diff$shifted))
@

We tested to see whether the unknown distributions of closer, further, and difference are consistent with the null hypothesis at the average. We used resampling to approximate the distribution and then stored the shifted resamples. The closer shifted mean is \Sexpr{mean(resamples.null.closer$shifted)}, further shifted mean is \Sexpr{mean(resamples.null.further$shifted)}, and the difference shifted mean is \Sexpr{mean(resamples.null.diff$shifted)}. All of these values are near zero which indicates that the resamples are consistent with the null.
 
  \item Compute the bootstrap $p$-value for each test using the shifted resamples. How do these compare to the $t$-test $p$-values?

<<message=F, warning=F, eval=T>>= 
# T-Test P-Value
t.p.close <- t.test(data$closer,
                     mu = 0,
                     alternative = "greater")$p.value

t.p.further <- t.test(data$further,
                      mu = 0,
                      alternative = "less")$p.value

t.p.diff <- t.test(data$diff,
                   mu = 0,
                   alternative = "two.sided")$p.value

# Bootstrap P-Value
boot.p.closer <- mean(resamples.null.closer$shifted >= closer.delta)

boot.p.further <- mean(resamples.null.further$shifted <= further.delta)

low <- 0 - diff.delta
high <- 0 + diff.delta
p.low <- mean(resamples.null.diff$shifted <= low)
p.high <- mean(resamples.null.diff$shifted >= high)
boot.p.diff <- p.low + p.high

(round(t.p.close, 4))
(boot.p.closer)
(round(t.p.further, 4))
(boot.p.further)
(round(t.p.diff, 4))
(boot.p.diff)
@

As can be seen, both the T-Test P-Values and Bootstrap P-Values are all near zero and are represented as zero when rounded to four decimal places.

    \item What is the 5$^{th}$ percentile of the shifted resamples under the null hypothesis? 
  Note this value approximates $t_{0.05, n-1}$. Compare these values in each case.

<<message=F, warning=F, eval=T>>= 
boot.closer.5th <- quantile(resamples.null.closer$shifted, 0.05)
t.closer.5th <- qt(0.05, df = num.closer -1)

boot.further.5th <- quantile(resamples.null.further$shifted, 0.05)
t.further.5th <- qt(0.05, df = num.further -1)

boot.diff.5th <- quantile(resamples.null.diff$shifted, 0.05)
t.diff.5th <- qt(0.05, df = num.diff -1)

(boot.closer.5th)
(t.closer.5th)
(boot.further.5th)
(t.further.5th)
(boot.diff.5th)
(t.diff.5th)
@

The bootstrapping $5^{th}$ percentile for the various cases are \Sexpr{boot.closer.5th} for the close, \Sexpr{boot.further.5th} for the further, and \Sexpr{boot.further.5th} for the difference. The t-test $5^{th}$ percentile for the various cases are \Sexpr{t.closer.5th} for the close, \Sexpr{t.further.5th} for the further, and \Sexpr{t.diff.5th} for the difference. As we can see, the bootstrapping and t-test $5^{th}$ percentiles are fairly similar to each other.

  \item Compute the bootstrap confidence intervals using the resamples. How do these 
  compare to the $t$-test confidence intervals?

<<message=F, warning=F, eval=T>>=  
boot.CI.closer <- quantile(resamples.null.closer$xbar, c(0.025, 0.975))
t.CI.closer <- t.test(x=data$closer, 
                      mu = 0, 
                      conf.level = 0.95, 
                      alternative = "two.sided")$conf.int

boot.CI.further <- quantile(resamples.null.further$xbar, c(0.025, 0.975))
t.CI.further <- t.test(x=data$further, 
                       mu = 0, 
                       conf.level = 0.95, 
                       alternative = "two.sided")$conf.int

boot.CI.diff <- quantile(resamples.null.diff$xbar, c(0.025, 0.975))
t.CI.diff <- t.test(x=data$diff, 
                    mu = 0, 
                    conf.level = 0.95, 
                    alternative = "two.sided")$conf.int

(boot.CI.closer)
(t.CI.closer)
(boot.CI.further)
(t.CI.further)
(boot.CI.diff)
(t.CI.diff)
@

As can be seen, the confidence intervals for each case are fairly similar between the bootstrap and t-test and do not differ by a large value.
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Question 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item Complete the following steps to revisit the analyses from lab 11 using the
randomization procedure.
\begin{enumerate}
\item Now, consider the zebra finch data. We do not know the generating distributions
for the closer, further, and difference data, so perform the randomization procedure

<<message=F, warning=F, eval=T>>=  
randomization.dist <- function(data, mu0, R = 10000) {
  random <- tibble(means = rep(NA, R))
  
  shifted.data <- data - mu0
  
  for(i in 1:R) {
    curr.random <- shifted.data * sample(x = c(-1, 1), 
                                         size = length(shifted.data), 
                                         replace = TRUE)
    random$means[i] <- mean(curr.random)
  }
  
  random <- random |>
    mutate(means = means + mu0)
  
  return(random)
}

closer.rand <- randomization.dist(data$closer, 0)
farther.rand <- randomization.dist(data$further, 0)
diff.rand <- randomization.dist(data$diff, 0)

(mean(closer.rand$means))
(mean(farther.rand$means))
(mean(diff.rand$means))
@

In this step, we found representative distribution for each case. As can be seen, each of the randomized distributions has a mean of about zero.

  \item Compute the randomization test $p$-value for each test.

<<message=F, warning=F, eval=T>>=    
closer.mean <- mean(data$closer)
closer.p.random <- mean(closer.rand$means >= closer.mean)

further.mean <- mean(data$further)
further.p.random <- mean(farther.rand$means <= further.mean)

diff.delta <- abs(mean(data$diff) - mu0)
mirror <- mu0 - diff.delta
xbar <- mu0 + diff.delta

diff.p.random <- mean(diff.rand$means <= mirror) + 
                 mean(diff.rand$means >= xbar)

(closer.p.random)
(further.p.random)
(diff.p.random)
@

All the p-values are zero which means there is statistically discernible support for the alternative hypothesis. The p-value of zero suggests that the observed mean is in the right tail for close, left tail for further, and in both tails for the difference.
  \item Compute the randomization confidence interval by iterating over values of $\mu_0$.\\
  \textbf{Hint:} You can ``search" for the lower bound from $Q_1$ and subtracting by 0.0001, 
  and the upper bound using $Q_3$ and increasing by 0.0001. You will continue until you find 
  the first value for which the two-sided $p$-value is greater than or equal to 0.05.

<<message=F, warning=F, eval=T>>=    
CI.finder <- function(data, R = 1000){
  
  mu0.iter <- 0.01
  mu0.lower <- mean(data)
  mu0.higher <- mean(data)
  
  repeat{
    random <- tibble(means = rep(NA, R))
    
    shifted.data <- data - mu0.lower
    
    for(i in 1:R) {
      curr.random <- shifted.data * sample(x = c(-1, 1), 
                                           size = length(shifted.data), 
                                           replace = TRUE)
      random$means[i] <- mean(curr.random)
    }
    
    random <- random |>
      mutate(means = means + mu0.lower)
    
    delta <- abs(mean(data) - mu0.lower)
    low <- mu0.lower - delta 
    high <- mu0.lower + delta   
    p.val <- mean(random$means <= low) +
             mean(random$means >= high)
    
    if(p.val < 0.05){
      break
    }else{
      mu0.lower <- mu0.lower - mu0.iter
    }
  }
  
  repeat{
    random <- tibble(means = rep(NA, R))
    
    shifted.data <- data - mu0.higher
    
    for(i in 1:R) {
      curr.random <- shifted.data * sample(x = c(-1, 1), 
                                           size = length(shifted.data), 
                                           replace = TRUE)
      random$means[i] <- mean(curr.random)
    }
    
    random <- random |>
      mutate(means = means + mu0.higher)
    
    delta <- abs(mean(data) - mu0.higher)
    low <- mu0.higher - delta 
    high <- mu0.higher + delta   
    p.val <- mean(random$means <= low) +
      mean(random$means >= high)
    
    if(p.val < 0.05){
      break
    }else{
      mu0.higher <- mu0.higher + mu0.iter
    }
  }
  
  return(c(mu0.lower, mu0.higher))
}

(close.CI.randomization <- CI.finder(data$closer))
(further.CI.randomization <- CI.finder(data$further))
(diff.CI.randomization <- CI.finder(data$diff))
@

The confidence intervals are (\Sexpr{close.CI.randomization[1]}, \Sexpr{close.CI.randomization[2]}) for close, (\Sexpr{further.CI.randomization[1]}, \Sexpr{further.CI.randomization[2]}) for further, and (\Sexpr{diff.CI.randomization[1]}, \Sexpr{diff.CI.randomization[2]}) for difference. These values are similar to those found earlier in the bootstrap and t-test methods.

\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Optional Question
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item \textbf{Optional Challenge:} In this lab, you performed resampling to 
approximate the sampling distribution of the $T$ statistic using
\[T = \frac{\bar{x}_r - 0}{s/\sqrt{n}}.\]
I'm curious whether it is better/worse/similar if we computed the statistics
using the sample standard deviation of the resamples ($s_r$), instead of the 
original sample ($s$)
  \[T = \frac{\bar{x}_r - 0}{s_r/\sqrt{n}}.\]
\begin{enumerate}
  \item Perform a simulation study to evaluate the Type I error for conducting this
hypothesis test both ways.
  \item Using the same test case(s) as part (a), compute bootstrap confidence 
  intervals and assess their coverage -- how often do we `capture' the parameter
of interest?
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% End Document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{enumerate}
\bibliography{bibliography}
\end{document}

